{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CourtSense MVP - Tennis Recovery Analyzer\n",
    "\n",
    "This notebook runs the tennis player tracking and coaching analysis on Google Colab.\n",
    "\n",
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q sam2 opencv-python-headless matplotlib numpy torch\n",
    "\n",
    "# Clone the repo\n",
    "!git clone https://github.com/fish5421/tennis_vision_app.git\n",
    "%cd tennis_vision_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Your Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"Upload your tennis video file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move to data folder\n",
    "video_filename = list(uploaded.keys())[0]\n",
    "shutil.move(video_filename, f\"data/{video_filename}\")\n",
    "VIDEO_PATH = f\"data/{video_filename}\"\n",
    "print(f\"\\nVideo saved to: {VIDEO_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract First Frame & Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read first frame\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if not ret:\n",
    "    raise ValueError(f\"Could not read video: {VIDEO_PATH}\")\n",
    "\n",
    "# Convert BGR to RGB for matplotlib\n",
    "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "print(f\"Video dimensions: {frame_width} x {frame_height}\")\n",
    "\n",
    "# Display the frame\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(frame_rgb)\n",
    "plt.title(\"First frame - note the court corners for next step\")\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Interactive Court Calibration\n",
    "\n",
    "**Click the 4 corners of the singles court in this order:**\n",
    "1. Bottom-Left (closest to camera, left side)\n",
    "2. Bottom-Right (closest to camera, right side)  \n",
    "3. Top-Right (far end, right side)\n",
    "4. Top-Left (far end, left side)\n",
    "\n",
    "**Wait for 4 clicks, then close the plot or wait for timeout.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Note: If %matplotlib notebook doesn't work, try %matplotlib inline and use the manual entry cell below\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLICK 4 COURT CORNERS in order:\")\n",
    "print(\"  1. Bottom-Left (near camera, left)\")\n",
    "print(\"  2. Bottom-Right (near camera, right)\")\n",
    "print(\"  3. Top-Right (far end, right)\")\n",
    "print(\"  4. Top-Left (far end, left)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.imshow(frame_rgb)\n",
    "ax.set_title(\"Click 4 court corners (BL -> BR -> TR -> TL)\")\n",
    "\n",
    "# Collect 4 points interactively\n",
    "court_corners = plt.ginput(4, timeout=120)  # 2 minute timeout\n",
    "plt.close()\n",
    "\n",
    "if len(court_corners) == 4:\n",
    "    court_corners = np.array(court_corners, dtype=np.float32)\n",
    "    print(f\"\\n✅ Court corners captured:\")\n",
    "    print(f\"   Bottom-Left:  ({court_corners[0][0]:.0f}, {court_corners[0][1]:.0f})\")\n",
    "    print(f\"   Bottom-Right: ({court_corners[1][0]:.0f}, {court_corners[1][1]:.0f})\")\n",
    "    print(f\"   Top-Right:    ({court_corners[2][0]:.0f}, {court_corners[2][1]:.0f})\")\n",
    "    print(f\"   Top-Left:     ({court_corners[3][0]:.0f}, {court_corners[3][1]:.0f})\")\n",
    "else:\n",
    "    print(f\"❌ Only got {len(court_corners)} points. Need 4. Run this cell again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Manual Corner Entry\n",
    "If interactive clicking doesn't work, enter coordinates manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL ENTRY - Uncomment and edit if interactive mode doesn't work\n",
    "# Look at the frame image above and estimate pixel coordinates\n",
    "\n",
    "# court_corners = np.array([\n",
    "#     [100, 650],   # Bottom-Left (x, y)\n",
    "#     [1100, 650],  # Bottom-Right\n",
    "#     [900, 300],   # Top-Right\n",
    "#     [300, 300],   # Top-Left\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "print(f\"Current court_corners: {court_corners}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Interactive Player Bounding Box Selection\n",
    "\n",
    "**Click 2 points to define a box around the player:**\n",
    "1. Top-left corner of box\n",
    "2. Bottom-right corner of box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLICK 2 POINTS to draw a box around the player:\")\n",
    "print(\"  1. Top-left corner of bounding box\")\n",
    "print(\"  2. Bottom-right corner of bounding box\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.imshow(frame_rgb)\n",
    "ax.set_title(\"Click top-left then bottom-right of player bounding box\")\n",
    "\n",
    "bbox_points = plt.ginput(2, timeout=120)\n",
    "plt.close()\n",
    "\n",
    "if len(bbox_points) == 2:\n",
    "    x1, y1 = bbox_points[0]\n",
    "    x2, y2 = bbox_points[1]\n",
    "    bbox = (int(min(x1,x2)), int(min(y1,y2)), int(abs(x2-x1)), int(abs(y2-y1)))\n",
    "    print(f\"\\n✅ Bounding box: x={bbox[0]}, y={bbox[1]}, w={bbox[2]}, h={bbox[3]}\")\n",
    "else:\n",
    "    print(\"❌ Need 2 points. Using auto-bbox instead.\")\n",
    "    bbox = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Manual BBox Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL ENTRY - Uncomment and edit if interactive mode doesn't work\n",
    "\n",
    "# bbox = (500, 400, 150, 300)  # (x, y, width, height)\n",
    "\n",
    "print(f\"Current bbox: {bbox}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Verify Selections Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Draw court corners and bbox on frame\n",
    "vis = frame_rgb.copy()\n",
    "\n",
    "# Draw court polygon\n",
    "pts = court_corners.astype(np.int32)\n",
    "for i, pt in enumerate(pts):\n",
    "    color = [(255,0,0), (0,255,0), (0,0,255), (255,255,0)][i]\n",
    "    cv2.circle(vis, tuple(pt), 10, color, -1)\n",
    "    cv2.putText(vis, f\"{i+1}\", (pt[0]+15, pt[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "cv2.polylines(vis, [pts], True, (0, 255, 0), 2)\n",
    "\n",
    "# Draw bbox\n",
    "if bbox:\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(vis, (x, y), (x+w, y+h), (255, 0, 255), 3)\n",
    "    cv2.putText(vis, \"Player\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(vis)\n",
    "plt.title(\"Verify: Green=Court, Magenta=Player BBox\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDoes this look correct? If not, re-run Steps 4 or 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compute Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Tennis court dimensions in meters\n",
    "COURT_WIDTH = 8.23\n",
    "COURT_LENGTH = 23.77\n",
    "\n",
    "# Destination points (real-world court corners)\n",
    "# Order: Bottom-Left, Bottom-Right, Top-Right, Top-Left\n",
    "dst_points = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [COURT_WIDTH, 0.0],\n",
    "    [COURT_WIDTH, COURT_LENGTH],\n",
    "    [0.0, COURT_LENGTH]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Compute homography\n",
    "H, _ = cv2.findHomography(court_corners, dst_points)\n",
    "\n",
    "print(\"✅ Homography matrix computed:\")\n",
    "print(H)\n",
    "\n",
    "# Save for later use\n",
    "np.save(\"data/homography.npy\", H)\n",
    "np.save(\"data/court_corners.npy\", court_corners)\n",
    "print(\"\\nSaved to data/homography.npy and data/court_corners.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Run Tracking & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.tracker import PlayerTracker\n",
    "from modules.calibration import pixel_to_meter\n",
    "from modules import geometry, coach\n",
    "import numpy as np\n",
    "\n",
    "# Load homography\n",
    "H = np.load(\"data/homography.npy\")\n",
    "\n",
    "# Initialize tracker\n",
    "print(\"Loading SAM2 model...\")\n",
    "tracker = PlayerTracker(model_id=\"facebook/sam2-hiera-small\")\n",
    "\n",
    "# Run tracking\n",
    "print(f\"\\nTracking player in {VIDEO_PATH}...\")\n",
    "bbox_str = f\"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]}\" if bbox else None\n",
    "\n",
    "tracking_frames, fps = tracker.track(\n",
    "    video_path=VIDEO_PATH,\n",
    "    display=False,  # No display in Colab\n",
    "    store_masks=False,\n",
    "    homography=H,\n",
    "    bbox=bbox,\n",
    "    allow_bbox_fallback=True,\n",
    "    max_frames=300,  # Adjust based on video length\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Tracked {len(tracking_frames)} frames at {fps:.1f} FPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Convert to Meter Coordinates & Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pixel coords to meters\n",
    "def fill_coords(tracking_frames, h_matrix):\n",
    "    coords_m = []\n",
    "    last_valid = None\n",
    "    for tf in tracking_frames:\n",
    "        if tf.centroid_px is not None:\n",
    "            metr = pixel_to_meter([tf.centroid_px], h_matrix)[0]\n",
    "            last_valid = metr\n",
    "        if last_valid is None:\n",
    "            coords_m.append(np.array([0.0, 0.0]))\n",
    "        else:\n",
    "            coords_m.append(last_valid)\n",
    "    return coords_m\n",
    "\n",
    "coords_m = fill_coords(tracking_frames, H)\n",
    "coords_m = np.array(coords_m)\n",
    "\n",
    "# Validate\n",
    "valid_centroids = sum(1 for tf in tracking_frames if tf.centroid_px is not None)\n",
    "print(f\"Valid centroids: {valid_centroids}/{len(tracking_frames)}\")\n",
    "print(f\"X range: {coords_m[:,0].min():.2f} to {coords_m[:,0].max():.2f} m\")\n",
    "print(f\"Y range: {coords_m[:,1].min():.2f} to {coords_m[:,1].max():.2f} m\")\n",
    "\n",
    "# Save\n",
    "np.save(\"data/coords_m.npy\", coords_m)\n",
    "print(\"\\nSaved to data/coords_m.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect shots and compute recovery\n",
    "shot_frames = geometry.detect_shots(coords_m, fps)\n",
    "print(f\"Detected {len(shot_frames)} shots\")\n",
    "\n",
    "ideal_pos = geometry.compute_dynamic_ideal_position(coords_m)\n",
    "print(f\"Dynamic ideal position: ({ideal_pos[0]:.2f}m, {ideal_pos[1]:.2f}m)\")\n",
    "\n",
    "recovery_stats = geometry.compute_recovery_times(coords_m, shot_frames, fps, ideal_position=ideal_pos)\n",
    "print(f\"\\nRecovery stats for {len(recovery_stats)} shots:\")\n",
    "for stat in recovery_stats:\n",
    "    print(f\"  Shot {stat['shot_id']}: {stat['time_to_recover']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Generate Coaching Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate coaching feedback (heuristic - no Ollama in Colab)\n",
    "feedback = coach.generate_feedback(recovery_stats, use_ollama=False, coords_m=coords_m)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COACHING FEEDBACK\")\n",
    "print(\"=\"*60)\n",
    "print(feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Top-Down Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Render top-down view\n",
    "topdown = geometry.render_topdown_path(coords_m, shot_frames)\n",
    "\n",
    "if topdown is not None:\n",
    "    # Convert BGR to RGB\n",
    "    topdown_rgb = cv2.cvtColor(topdown, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(8, 12))\n",
    "    plt.imshow(topdown_rgb)\n",
    "    plt.title(\"Player Movement Path (Top-Down View)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save\n",
    "    cv2.imwrite(\"data/topdown_path.png\", topdown)\n",
    "    print(\"Saved to data/topdown_path.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the results\n",
    "files.download(\"data/topdown_path.png\")\n",
    "files.download(\"data/coords_m.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
